{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assoziationsanalysen\n",
    "\n",
    "Bei dieser Art der Analyse spricht man häufig auch von *Warenkorbanalyse* (engl. *market basket analysis*),\n",
    "da der anfangs häufigste Anwendungsfall der ist, dass man wissen möchte, welche Artikel aus einem Sortiment\n",
    "besonders häufig gemeinsam erworben werden, um daraus dann geschäftssteigernde Aktivitäten abzuleiten.\n",
    "\n",
    "Es geht also darum, *Regeln* der Form \"Wenn $X$, dann $Y$\"\n",
    "aufzustellen (kurz $X \\rightarrow Y$), wobei $X$ und $Y$ sogenannte *Itemmengen*\n",
    "repräsentieren. Der Begriff *Item* ist dabei der Fachausdruck für einen\n",
    "Untersuchungsgegenstand. In der Warenkorbanalyse sind diese Items beispielsweise Artikel in einem\n",
    "Supermarkt oder bei einem Onlinehändler. So ist wohl jedem auch bereits die Nutzung derartiger\n",
    "Regeln begegnet: Beim Online-Einkauf erhält man *Kaufempfehlungen* für Produkte, die\n",
    "demjenigen, für das man sich interessiert, ähnlich sind oder aber dieses ggf. ergänzen.\n",
    "Geschäftsziel derartiger Warenkorbanalysen ist also das *Cross-Selling*.\n",
    "\n",
    "Die gesuchten Regeln müssen quasi ohne Vorkenntnisse aus den vorhandenen Verkaufsdaten\n",
    "herausgefiltert werden. Daher handelt es sich bei der Assoziationsanalyse um ein Verfahren des\n",
    "*unüberwachten Lernens*.\n",
    "\n",
    "Zur Illustration betrachten wir die folgende Tabelle. Beim Einkauf mit *BelegNr* 47110816\n",
    "werden die Artikel mit den Nummern 2 und 530 also zusammen erworben (möglicherweise handelt es sich\n",
    "ja um Bier und Windeln ...)\n",
    "\n",
    "\n",
    "  BelegNr  | KundenNr | ArtikelNr | Menge\n",
    ":---------:|:--------:|:---------:|:-------\n",
    "47110815 |\t\t649 |\t\t30 |\t\t4\n",
    "47110816 |\t\t563 |\t\t2 |\t\t1\n",
    "47110816 |\t\t563 |\t\t530 |\t\t2\n",
    "47110817 |\t\t43 |\t\t122 |\t\t3\n",
    "... |\t\t... |\t\t... |\t\t...\n",
    "\n",
    "\n",
    " Im Folgenden betrachten wir noch näher, welche\n",
    "Berechnungen Warenkorbanalysen erfordern.\n",
    "\n",
    "## Objekte von Warenkorbanalysen\n",
    "\n",
    "Den Untersuchungen zugrunde liegt immer eine Itemmenge $I = \\{ i_1, i_2, \\dots, i_m\\}$ von $m$ Items\n",
    "$i_k,\\ k=1,\\dots,m$. Es werden dann *Transaktionen* $T\\subseteq I$ betrachtet. Diese\n",
    "repräsentieren bei der klassischen Warenkorbanalyse den Einkauf eines Kunden, bei dem (normalerweise\n",
    "mehrere) Artikel ($\\hat=$ Items) zusammen gekauft werden. Im Allgemeinen repräsentieren sie\n",
    "Ereignisse, bei denen Untersuchungsgegenstände gemeinsam auftreten. Untersucht wird schließlich eine\n",
    "*Datenbank* $D = \\{ T_1, T_2, ..., T_n\\}$ von $n$ Transaktionen $T_j,\\ j=1,\\dots,n$, die auch\n",
    "*Population* genannt wird. Gesucht werden dann Regeln\n",
    "\n",
    "$$\n",
    " X \\rightarrow Y\\quad\\text{mit}\\quad X,Y \\subseteq I\\quad\\text{und}\\quad X\\cap Y = \\emptyset\n",
    "$$\n",
    "\n",
    "d.h. $X$ und $Y$ müssen *disjunkt* sein. Dabei spricht man von $X$ als dem *Kopf*\n",
    "(bzw. der *Voraussetzung*) der Regel, während $Y$ der *Körper* (bzw. der *Schluss*\n",
    "(im Sinne des logischen Schließens)) der Regel ist. \n",
    "\n",
    "Die Forderung nach der leeren Schnittmenge von $X$ und $Y$ bedeutet im Rahmen der klassischen\n",
    "Warenkorbanalyse, dass ein Artikel nicht sowohl im Kopf als auch im Körper der Regel vorkommen darf.\n",
    "Das würde aber auch keinen Sinn ergeben, denn für ein Item $i$ ist natürlich die Regel\n",
    "$\\{i\\}\\rightarrow\\{i\\}$ immer erfüllt, denn $i$ kommt natürlich immer mit sich selbst vor.\n",
    "\n",
    "## Kennzahlen von Warenkorbanalysen\n",
    "\n",
    "Die wichtigsten Kenngrößen sind zunächst\n",
    "* der *Support* ($=$ relative Häufigkeit in der Population)\n",
    "$$\n",
    "       \\begin{aligned}\n",
    "         \\text{sup}(X) & = \\frac{\\lvert\\lbrace T \\in D \\mid X \\subseteq T \\rbrace\\rvert}{\\lvert D \\rvert}\\\\\n",
    "         \\text{sup}(X \\rightarrow Y) & = \\frac{\\lvert\\lbrace T \\in D \\mid X \\cup Y \\subseteq T \\rbrace\\rvert}{\\lvert D \\rvert}\n",
    "         = \\text{sup}(X\\cup Y) = \\text{sup}(Y \\rightarrow X)\n",
    "       \\end{aligned}\n",
    "$$\n",
    "* die *Confidence* ($=$ relative Häufigkeit im $X$-Teil der Population)\n",
    "$$\n",
    "       \\text{conf}(X \\rightarrow Y) = \n",
    "         \\frac{\\lvert\\lbrace T \\in D \\mid X \\cup Y \\subseteq T \\rbrace\\rvert}{\\lvert\\lbrace T \\in D \\mid X \\subseteq T \\rbrace\\rvert} =\n",
    "         \\frac{\\text{sup}(X \\rightarrow Y)}{\\text{sup}(X)}\n",
    "$$\n",
    "\n",
    " \n",
    "Man sollte sich bei diesen Formeln vor allem klar machen, dass immer die folgende ***Hinzunahmeungleichung*** gilt\n",
    " \n",
    "$$\n",
    "\\text{sup}(X\\rightarrow Y) \\leq \\text{sup}(X)\\qquad(1)\n",
    "$$\n",
    " \n",
    "denn $X \\cup Y \\subseteq T$ ist eine stärker einschränkende Bedingung als $X \\subseteq T$. Denn wenn man noch weitere Items zu einer Transaktion hinzunimmt, also mehr Items gleichzeitig in einer Transaktion vorkommen müssen, was der Fall ist, wenn $X$ und $Y$ zusammen betrachtet werden, im Vergleich zu dem Fall, wenn nur $X$ betrachtet wird. Die Aussage der *Hinzunahmeungleichung* ist also einfach, dass alle Artikel aus $X$ und $Y$ zusammen höchstens so häufig gekauft werden wie die Artikel aus $X$ alleine. Daraus ergibt sich insbesondere, dass \n",
    " \n",
    "$$\n",
    "0 \\leq \\text{sup}(X),\\quad \\text{conf}(X\\rightarrow Y) \\leq 1\n",
    "$$\n",
    "\n",
    "d.h. sowohl *Support* als auch *Confidence* können nur Werte zwischen 0 und 1 annehmen\n",
    "(was natürlich auch aus deren Interpretation als relative Häufigkeiten folgt).\n",
    "\n",
    "Ferner ist zu beachten, dass man den *Support* auch als *erwartete Confidence*\n",
    "interpretieren kann. Hat man nämlich eine *leere Voraussetzung* (also keine näheren\n",
    "Informationen über die Population), dann muss man die gesamte Population betrachten. Somit kann man\n",
    "festhalten\n",
    "\n",
    "$$\n",
    "\\text{sup}(X) = \\text{conf}_{\\text{exp}}(X)\n",
    "$$\n",
    "\n",
    "Hieraus lässt sich nun ein weiteres *Interessantheitsmaß* für eine Regel ableiten, der sogenannte\n",
    "*Lift*. Es handelt sich dabei um ein Konzept, welches ursprünglich aus dem Marketing stammt und\n",
    "hinter dem allgemein die Frage steht, wieviel \"besser\" (in welchem Sinne auch immer) wir\n",
    "sind, wenn uns gewisse Informationen vorliegen, als wenn wir ohne diese Information auskommen\n",
    "müssten (letzlich also ein ähnliches Konzept wie der *Informationsgewinn* bei Entscheidungsbäumen).\n",
    "In unserem Kontext wird der Lift berechnet als das\n",
    "Verhältnis der Confidence und der erwarteten Confidence, also\n",
    "\n",
    "\\begin{aligned}\n",
    " \\text{lift}(X \\rightarrow Y) = \\frac{\\text{conf}(X \\rightarrow Y)}{\\text{conf}_{\\text{exp}}(Y)} \n",
    "                         &= \\frac{\\text{conf}(X \\rightarrow Y)}{\\text{sup}(Y)} \\\\\n",
    "                         &= \\frac{\\text{sup}(X \\cup Y)}{\\text{sup}(X)\\cdot\\text{sup}(Y)}\n",
    "                          = \\text{lift}(Y \\rightarrow X)\n",
    "\\end{aligned}\n",
    "\n",
    "Es ergibt sich damit unmittelbar folgende Interpretation:\n",
    "* $\\text{lift}(X \\rightarrow Y ) > 1$: *Komplementäreffekt*\n",
    "* $\\text{lift}(X \\rightarrow Y ) < 1$: *Substitutionseffekt*\n",
    "\n",
    "d.h., wenn der Lift größer als 1 ist, dann verbessert sich die Chance, auch die Artikel aus $Y$ zu\n",
    "verkaufen, wenn man bereits weiß, dass die Artikel in $X$ gekauft wurden, im anderen Fall\n",
    "verschlechtert sie sich.\n",
    "\n",
    "**Bemerkung:** Betrachtet man die Formeln für Support, Confidence und Lift nochmal, so sieht man, dass Support\n",
    "     und Lift *symmetrisch* bezüglich Voraussetzung und Schluss der Regel sind, während es bei\n",
    "     der Confidence sehr wohl darauf ankommt, was die Voraussetzung und was der Schluss ist.\n",
    "\n",
    "### Beispiel\n",
    "Wir nehmen das berühmte Bier-und-Windeln-Beispiel und unterfüttern es mit Zahlen. Dabei gehen wir\n",
    "davon aus, dass bereits die *Datenbank* durchstöbert wurde und bei den Zählungen die in der folgenden\n",
    "Tabelle angegebenen Zahlen herauskamen. \n",
    "\n",
    "\n",
    "   Transaktionen | Anzahl\n",
    ":--------------- | ----------------:\n",
    "Gesamt |    3.000.000\n",
    "Bier (B) |    300.000\n",
    "Windeln (W) | 500.000\n",
    "B & W | 150.000\n",
    "\n",
    "Hieraus lassen sich also die Kenngrößen *Support, Confidence* und *Lift* berechnen.\n",
    "\n",
    "Es ergibt sich:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\text{sup}(B) &= \\frac{300.000}{3.000.000} = 10\\%\\\\\n",
    "\\text{sup}(W) &= \\frac{500.000}{3.000.000} = 16.67\\%\\\\\n",
    "\\text{sup}(W\\rightarrow B) &= \\frac{150.000}{3.000.000} = 5\\% = \\text{sup}(B\\rightarrow W)\\\\\n",
    "\\text{conf}(W \\rightarrow B) & = \\frac{150.000}{500.000} = 30\\%\\\\\n",
    "\\text{conf}(B \\rightarrow W) & = \\frac{150.000}{300.000} = 50\\%\\\\\n",
    "\\text{lift}(W \\rightarrow B) & = \\frac{\\text{conf}(W \\rightarrow B)}{\\text{conf}_{\\text{exp}}(B)} \n",
    "                               = \\frac{30\\%}{10\\%} = 3 = \\text{lift}(B \\rightarrow W)\n",
    "\\end{aligned}\n",
    "\n",
    "Die Zuversicht, wenn Bier gekauft ist, auch Windeln zu verkaufen können, ist also höher (50\\%) als\n",
    "im umgekehrten Fall (30\\%). Allerdings verdreifacht sich also die Chance, Bier zu verkaufen, wenn\n",
    "Windeln gekauft werden!\n",
    "\n",
    "## A-priori Algorithmus\n",
    "\n",
    "So trivial die Beobachtung der *Hinzunahmeungleichung* (1) und deren Interpretation auch erscheinen\n",
    "mag, sie bildet doch die Grundlage des sogenannten *A-priori Algorithmus*, auf dem viele\n",
    "Algorithmen zur Assoziationsanalyse basieren. Die Idee ist dabei bestechend einfach. Zunächst wird\n",
    "eine *Untergrenze für den Support* angegeben, damit eine Regel überhaupt in Betracht gezogen\n",
    "wird. Man sucht dann nach sogenannten *großen Itemmengen* (engl. *large itemsets*). Dabei\n",
    "ist eine Itemmenge genau dann groß, wenn ihr Support den geforderten Mindestsupport nicht\n",
    "unterschreitet.\n",
    "\n",
    "Geht man diese Suche nun naiv an, dann erhält man einen Algorithmus mit sehr hoher Komplexität,\n",
    "d.h. die Laufzeiten wachsen immens. Hier kommt nun wieder die *Hinzunahmeungleichung* (1) ins Spiel, denn\n",
    "aus ihr folgt, dass eine Itemmenge nur dann groß sein kann, wenn *jede Teilmenge* dieser\n",
    "Itemmenge *groß* ist. Somit lassen sich also zunächst die einelementigen großen Itemmengen\n",
    "finden, d.h. diejenigen Artikel, die oft genug gekauft werden. Jede zweielementige große Itemmenge\n",
    "muss sich aus diesen Artikeln kombinieren lassen, wobei hier wiederum nicht alle Kombinationen groß\n",
    "sein werden. Der Algorithmus stoppt also recht bald und man kann dann alle disjunkten Teilmengen der\n",
    "großen Itemmengen zur Regelgenerierung untersuchen.\n",
    "\n",
    "Für die Ermittlung der eigentlichen Regeln wird neben dem Mindestsupport auch eine\n",
    "*Mindestconfidence* sowie häufig auch die Maximalzahl der Items in den großen Itemmengen\n",
    "angegeben.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Als nächstes schauen wir uns die [praktische Umsetzung in R](2017-12-15_RvS_Assoziationsanalysen_R.ipynb) an."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
